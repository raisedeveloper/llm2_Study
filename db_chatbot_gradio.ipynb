{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBì ‘ì† ì±—ë´‡ ì˜ˆì œ(Gradio ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\aiproject\\llm2_Study\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager # ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ì— ëŒ€í•œ ì½œë°±ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler  # í…ìŠ¤íŠ¸ ìƒì„±ë˜ëŠ” ëŒ€ë¡œ ë°”ë¡œ ì¶œë ¥\n",
    "import re  # í…ìŠ¤íŠ¸ íŒ¨í„´ì„ ì •ì˜ (í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰, ì¹˜í™˜, ë¶„ë¦¬)\n",
    "from typing import Dict, Any  # íƒ€ì…ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ì½”ë“œì˜ ê°€ë…ì„±ê³¼ ì•ˆì •ì„±ì„ ë†’ì„\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB ì—°ê²° ì„¤ì •\n",
    "DB_URL = \"mysql+pymysql://root:dhforkwk96$@localhost:3306/test\"\n",
    "engine = create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedQueryGenerator:\n",
    "    \"\"\"í–¥ìƒëœ SQL ì¿¼ë¦¬ ìƒì„± í´ë˜ìŠ¤\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.query_template = \"\"\"\n",
    "        ë‹¹ì‹ ì€ í•œêµ­ì–´ë¥¼ ì˜í•˜ê³  MySQL ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´:\n",
    "        {schema_info}\n",
    "\n",
    "        ì´ì „ í”¼ë“œë°± ì •ë³´:\n",
    "        {feedback_info}\n",
    "\n",
    "        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ MySQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "        ì§ˆë¬¸: {question}\n",
    "\n",
    "        ê·œì¹™:\n",
    "        1. ìˆœìˆ˜í•œ SQL ì¿¼ë¦¬ë§Œ ì‘ì„±í•˜ì„¸ìš”\n",
    "        2. ì»¬ëŸ¼ì˜ ì‹¤ì œ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "        3. ì„¤ëª…ì´ë‚˜ ì£¼ì„ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n",
    "        4. ì¿¼ë¦¬ëŠ” SELECT ë¬¸ìœ¼ë¡œ ì‹œì‘í•˜ê³  ì„¸ë¯¸ì½œë¡ (;)ìœ¼ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤\n",
    "        5. WHERE ì ˆì—ì„œëŠ” ì •í™•í•œ ê°’ ë§¤ì¹­ì„ ìœ„í•´ = ì—°ì‚°ìë¥¼ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "        6. ìœ ì‚¬ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° LIKE '%í‚¤ì›Œë“œ%' ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "        7. ê´€ë ¨ëœ ëª¨ë“  ê²°ê³¼ë¥¼ ì°¾ê¸° ìœ„í•´ ì ì ˆíˆ OR ì¡°ê±´ì„ í™œìš©í•˜ì„¸ìš”\n",
    "        \"\"\"\n",
    "\n",
    "        self.answer_template = \"\"\"\n",
    "        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "        ì›ë˜ ì§ˆë¬¸: {question}\n",
    "        ì‹¤í–‰ëœ ì¿¼ë¦¬: {query}\n",
    "        ì¿¼ë¦¬ ê²°ê³¼: {result}\n",
    "\n",
    "        ê·œì¹™:\n",
    "        1. ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
    "        2. ìˆ«ì ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì ì ˆí•œ ë‹¨ìœ„ì™€ í•¨ê»˜ í‘œí˜„í•´ì£¼ì„¸ìš”\n",
    "        3. ê²°ê³¼ê°€ ì—†ë‹¤ë©´ ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
    "        4. ì „ë¬¸ì ì¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
    "        \"\"\"\n",
    "\n",
    "        # Gemma2 ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "        self.llm = Ollama(\n",
    "            model=\"gemma2\",\n",
    "            temperature=0,\n",
    "            callback_manager=callback_manager\n",
    "        )\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "        self.query_prompt = ChatPromptTemplate.from_template(self.query_template)\n",
    "        self.answer_prompt = ChatPromptTemplate.from_template(self.answer_template)\n",
    "\n",
    "        # Chain ì„¤ì •\n",
    "        self.query_chain = LLMChain(llm=self.llm, prompt=self.query_prompt)\n",
    "        self.answer_chain = LLMChain(llm=self.llm, prompt=self.answer_prompt)\n",
    "\n",
    "    def generate_query(self, question: str, schema_info: str, feedback_info: str = \"\") -> str:\n",
    "        \"\"\"ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "        response = self.query_chain.run(\n",
    "            question=question,\n",
    "            schema_info=schema_info,\n",
    "            feedback_info=feedback_info\n",
    "        )\n",
    "        return self.extract_sql_query(response)\n",
    "\n",
    "    def generate_answer(self, question: str, query: str, result: Any) -> str:\n",
    "        \"\"\"ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "        result_str = str(result) if isinstance(result, pd.DataFrame) else json.dumps(result, ensure_ascii=False)\n",
    "        response = self.answer_chain.run(\n",
    "            question=question,\n",
    "            query=query,\n",
    "            result=result_str\n",
    "        )\n",
    "        return response.strip()\n",
    "\n",
    "    @staticmethod  # ë©”ì„œë“œê°€ í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ ì—†ì´ë„ í˜¸ì¶œ\n",
    "    def extract_sql_query(response: str) -> str:\n",
    "        \"\"\"ì‘ë‹µì—ì„œ SQL ì¿¼ë¦¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\"\"\"\n",
    "        response = response.replace('```sql', '').replace('```', '').strip()\n",
    "        match = re.search(r'SELECT.*?;', response, re.DOTALL | re.IGNORECASE)\n",
    "        return match.group(0).strip() if match else response.strip()\n",
    "\n",
    "# ì¿¼ë¦¬ ê²°ê³¼ ë°˜í™˜\n",
    "def get_schema_info():\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        tables = pd.read_sql(\"SHOW TABLES\", conn)\n",
    "        schema_info = []\n",
    "\n",
    "        for table in tables.iloc[:, 0]:\n",
    "            columns = pd.read_sql(f\"DESCRIBE {table}\", conn)\n",
    "            schema_info.append(f\"í…Œì´ë¸”: {table}\")\n",
    "            schema_info.append(\"ì»¬ëŸ¼:\")\n",
    "            for _, row in columns.iterrows():\n",
    "                schema_info.append(f\"- {row['Field']} ({row['Type']})\")\n",
    "            schema_info.append(\"\")\n",
    "\n",
    "        return \"\\n\".join(schema_info)\n",
    "\n",
    "def execute_query(query):\n",
    "    \"\"\"SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = pd.read_sql(query, conn)\n",
    "            return result\n",
    "    except Exception as e:\n",
    "        return f\"ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
    "\n",
    "def process_question(question):\n",
    "    \"\"\"ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    schema_info = get_schema_info()\n",
    "    query_generator = EnhancedQueryGenerator()\n",
    "\n",
    "    # ì¿¼ë¦¬ ìƒì„±\n",
    "    query = query_generator.generate_query(question, schema_info)\n",
    "\n",
    "    # ì¿¼ë¦¬ ì‹¤í–‰\n",
    "    result = execute_query(query)\n",
    "\n",
    "    # ë‹µë³€ ìƒì„±\n",
    "    answer = query_generator.generate_answer(question, query, result)\n",
    "\n",
    "    return query, result, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "def create_interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"# DB ë¬¸ì˜ ì±—ë´‡ (Gemma2 ê¸°ë°˜)\")\n",
    "\n",
    "        with gr.Row():\n",
    "            question_input = gr.Textbox(\n",
    "                label=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\",\n",
    "                placeholder=\"ë°ì´í„°ë² ì´ìŠ¤ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”...\"\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            submit_btn = gr.Button(\"ì§ˆë¬¸í•˜ê¸°\")\n",
    "\n",
    "        with gr.Row():\n",
    "            query_output = gr.Textbox(label=\"ìƒì„±ëœ SQL ì¿¼ë¦¬\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_output = gr.Dataframe(label=\"ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼\")\n",
    "\n",
    "        with gr.Row():\n",
    "            answer_output = gr.Textbox(\n",
    "                label=\"AI ë‹µë³€\",\n",
    "                lines=5\n",
    "            )\n",
    "\n",
    "        submit_btn.click(\n",
    "            fn=process_question,\n",
    "            inputs=[question_input],\n",
    "            outputs=[query_output, result_output, answer_output]\n",
    "        )\n",
    "\n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yj\\AppData\\Local\\Temp\\ipykernel_17952\\3742907263.py:42: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  self.llm = Ollama(\n",
      "C:\\Users\\yj\\AppData\\Local\\Temp\\ipykernel_17952\\3742907263.py:42: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  self.llm = Ollama(\n",
      "C:\\Users\\yj\\AppData\\Local\\Temp\\ipykernel_17952\\3742907263.py:53: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  self.query_chain = LLMChain(llm=self.llm, prompt=self.query_prompt)\n",
      "C:\\Users\\yj\\AppData\\Local\\Temp\\ipykernel_17952\\3742907263.py:58: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = self.query_chain.run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM elec_forecast WHERE Date = '2023-10-26' \n",
      "\n",
      "\n",
      "2023ë…„ 10ì›” 26ì¼ì˜ ë°œì „ëŸ‰ ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ì°¾ì•„ë´¤ëŠ”ë°, ì•„ì§ ì •ë³´ê°€ ì—†ì–´ìš”.  \n",
      "\n",
      "ë§ˆì¹˜ ë¯¸ë˜ì— ëŒ€í•œ ì±…ì´ ì•„ì§ ì“°ì—¬ì§€ì§€ ì•Šì•˜ë‹¤ëŠ” ê²ƒê³¼ ê°™ì•„ìš”! ğŸ˜Š  \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yj\\AppData\\Local\\Temp\\ipykernel_17952\\3742907263.py:42: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  self.llm = Ollama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * \n",
      "FROM elec_forecast\n",
      "WHERE Date = '2023-01-01';  \n",
      "2023ë…„ 1ì›” 1ì¼ ë‚ ì§œì— ëŒ€í•œ ì „ë ¥ ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ì°¾ì•„ë³´ì•˜ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, í˜„ì¬ ë°ì´í„°ì—ëŠ” 2023ë…„ 1ì›” 1ì¼ì˜ ì „ë ¥ ì˜ˆì¸¡ ì •ë³´ê°€ ì—†ì–´ ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yj\\AppData\\Local\\Temp\\ipykernel_17952\\3742907263.py:42: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  self.llm = Ollama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * \n",
      "FROM elec_forecast\n",
      "WHERE Date = '2020-01-01';  \n",
      "2020ë…„ 1ì›” 1ì¼ ë‚ ì§œì— ëŒ€í•œ ì „ë ¥ ì˜ˆì¸¡ ë°ì´í„°ëŠ” ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  \n",
      "\n",
      "'elec_forecast' í…Œì´ë¸”ì—ì„œ 'Date' ì—´ì´ 2020ë…„ 1ì›” 1ì¼ì¸ í–‰ì€ ì—†ì–´ì„œ ê²°ê³¼ê°€ ë¹„ì—ˆì£ . ë§ˆì¹˜ ì±…ì¥ì— íŠ¹ì • ì±…ì´ ì—†ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.  \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yj\\AppData\\Local\\Temp\\ipykernel_17952\\3742907263.py:42: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  self.llm = Ollama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * \n",
      "FROM elec_forecast\n",
      "WHERE Date = '2020-01-01';  \n",
      "2020ë…„ 1ì›” 1ì¼ ë‚ ì§œì— ëŒ€í•œ ì „ë ¥ ì˜ˆì¸¡ ë°ì´í„°ëŠ” ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  \n",
      "\n",
      "'elec_forecast' í…Œì´ë¸”ì—ì„œ 'Date' ì—´ì´ 2020ë…„ 1ì›” 1ì¼ì¸ í–‰ì€ ì—†ì–´ì„œ ê²°ê³¼ê°€ ë¹„ì—ˆì£ . ë§ˆì¹˜ ì±…ì¥ì— íŠ¹ì • ì±…ì´ ì—†ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.  \n",
      "\n",
      "\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    demo = create_interface()\n",
    "    demo.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "#demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
