{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 분류 예제(Gradio + gemma2 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\aiproject\\llm2_Study\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow MobileNetV2 모델 로드\n",
    "model = tf.keras.applications.MobileNetV2(weights=\"imagenet\")  # 사전 훈련된 가중치를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_SERVER = \"http://localhost:11434\"  # 로컬 서버 주소\n",
    "MODEL_NAME = \"gemma2\"  # 사용하려는 Ollama 모델 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama를 사용해 음식 설명 생성\n",
    "def get_food_description_with_langchain(food_name):\n",
    "    \"\"\"\n",
    "    LangChain ChatOllama를 사용하여 음식 설명 생성\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chat = ChatOllama(base_url=OLLAMA_SERVER, model=MODEL_NAME)\n",
    "        prompt = f\"{food_name}에 대해 특징, 효능, 요리 레시피 설명해줘.설명은 한국어로 해줘.\"\n",
    "        response = chat.predict(prompt)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Failed to retrieve description: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 예측 함수\n",
    "def predict_image_with_description(image_url):\n",
    "    \"\"\"\n",
    "    이미지 URL을 받아 음식 예측과 Ollama 설명을 반환\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # URL에서 이미지 가져오기\n",
    "        response = requests.get(image_url)\n",
    "        image = Image.open(BytesIO(response.content)).resize((224, 224))  # BytesIO 사용하여 이미지 열기\n",
    "\n",
    "        # 이미지를 배열로 변환\n",
    "        image_array = tf.keras.preprocessing.image.img_to_array(image)  # 이미지를 숫자 배열로 전환\n",
    "        image_array = tf.expand_dims(image_array, axis=0)  # 모델이 한 번에 여러 이미지를 처리할 수 있게 \"배치\"라는 차원을 추가\n",
    "        image_array = tf.keras.applications.mobilenet_v2.preprocess_input(image_array)  # 이미지 픽셀 값을 모델이 학습할 때 사용했던 범위로 조정 전처리\n",
    "\n",
    "        # 예측 수행\n",
    "        predictions = model.predict(image_array)\n",
    "        decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]  # 상위 3개 예측 결과 반환\n",
    "\n",
    "        # 예측 결과 형식화\n",
    "        result = {label: float(prob) for (_, label, prob) in decoded_predictions} # 예측 결과를 Gradio의 Label 컴포넌트가 요구하는 형식으로 변환\n",
    "\n",
    "        # 가장 높은 확률의 예측값으로 Ollama 설명 생성\n",
    "        top_food = decoded_predictions[0][1]  # 가장 확률이 높은 음식 이름\n",
    "        description = get_food_description_with_langchain(top_food)\n",
    "\n",
    "        return result, description  # 예측 결과와 Ollama 설명 반환\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": 1.0}, f\"Error: {e}\"  # 에러 발생 시 기본값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio 인터페이스 생성\n",
    "iface = gr.Interface(\n",
    "    fn=predict_image_with_description,\n",
    "    inputs=gr.Textbox(label=\"이미지 URL 입력\"),\n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=3, label=\"예측 결과\"),  # 상위 3개 예측 결과\n",
    "        gr.Textbox(label=\"음식 설명\", interactive=False)  # Ollama로 생성한 설명 출력\n",
    "    ],\n",
    "    title=\"음식 이미지 분류 및 설명 생성기\",\n",
    "    description=\"이미지 URL을 입력하면 음식 분류 결과와 설명을 제공합니다.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인터페이스 실행\n",
    "iface.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "iface.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
